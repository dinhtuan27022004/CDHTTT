"""
services/query_expansion.py â€“ Má»Ÿ rá»™ng truy váº¥n báº±ng cÃ¡c tá»« Ä‘á»“ng nghÄ©a phÃ¡p lÃ½.
"""

from __future__ import annotations
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from services.openrouter_service import get_llm

EXPANSION_PROMPT = ChatPromptTemplate.from_messages([
    ("system", """Báº¡n lÃ  chuyÃªn gia ngÃ´n ngá»¯ phÃ¡p lÃ½ Viá»‡t Nam. 
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  láº¥y má»™t cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ  má»Ÿ rá»™ng nÃ³ báº±ng cÃ¡c thuáº­t ngá»¯ Ä‘á»“ng nghÄ©a, cÃ¡c khÃ¡i niá»‡m tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c tá»« khÃ³a trong cÃ¢u há»i, má»Ÿ rá»™ng cÃ¡c cÃ¢u há»i ngáº¯n, thiáº¿u.

QUY Táº®C:
1. Tráº£ vá» má»™t chuá»—i duy nháº¥t chá»©a cÃ¡c tá»« má»Ÿ rá»™ng (khÃ´ng láº·p láº¡i cÃ¢u gá»‘c).
2. Táº­p trung vÃ o cÃ¡c thuáº­t ngá»¯ chuyÃªn mÃ´n cÃ³ kháº£ nÄƒng xuáº¥t hiá»‡n trong vÄƒn báº£n luáº­t vÃ  pháº£i Ä‘áº£m báº£o liÃªn quan tá»›i cÃ¢u há»i ngÆ°á»i dÃ¹ng.
3. KHÃ”NG tráº£ lá»i cÃ¢u há»i, chá»‰ má»Ÿ rá»™ng tá»« khÃ³a.
4. Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng danh sÃ¡ch tá»« khÃ³a cÃ¡ch nhau bá»Ÿi dáº¥u pháº©y hoáº·c khoáº£ng tráº¯ng.
5. khÃ´ng má»Ÿ rá»™ng cÃ¡c tá»« khÃ³a khÃ´ng liÃªn quan tá»›i cÃ¢u há»i ngÆ°á»i dÃ¹ng.
VÃ­ dá»¥:
Input: "láº¥y trá»™m xe mÃ¡y"
Output: "trá»™m cáº¯p tÃ i sáº£n, chiáº¿m Ä‘oáº¡t tÃ i sáº£n, tá»™i trá»™m cáº¯p"
"""),
    ("human", "{question}")
])

def expand_query_for_search(question: str) -> str:
    """
    Sá»­ dá»¥ng LLM (model nhanh + á»•n Ä‘á»‹nh) Ä‘á»ƒ sinh ra cÃ¡c thuáº­t ngá»¯ Ä‘á»“ng nghÄ©a.
    """
    try:
        # Sá»­ dá»¥ng gpt-4o-mini vÃ¬ Gemini Flash Ä‘ang gáº·p lá»—i endpoint 404 trÃªn OpenRouter
        llm = get_llm(model_name="openai/gpt-4o-mini")
        chain = EXPANSION_PROMPT | llm | StrOutputParser()
        expanded = chain.invoke({"question": question})
        print(f"ğŸš€ Expanded Query: {expanded}")
        return f"{question} {expanded.strip()}"
    except Exception as e:
        print(f"âš ï¸ Query Expansion error: {e}")
        return question
